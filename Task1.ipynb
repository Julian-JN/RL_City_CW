{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f757465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dc15e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
      "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
      "       [0, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
      "       [1, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 1, 1, 0, 0, 1, 0, 1],\n",
      "       [1, 0, 1, 0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 0, 1, 0, 0, 0, 1]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze_size = (10, 10)  \n",
    "maze_rand = np.random.choice([0, 1], size=maze_size)\n",
    "print(repr(maze_rand))\n",
    "plt.imshow(maze_rand, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7870cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (7, 0), (7, 1), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (8, 0), (8, 1), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7), (8, 8), (8, 9), (9, 0), (9, 1), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9), (7, 5)]\n",
      "(101, 4)\n",
      "Q matrix: \n",
      "\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "class Maze_env:\n",
    "    def __init__(self , start, target, coins, maze):\n",
    "        self.maze = maze\n",
    "        self.target = target\n",
    "        self.start = start\n",
    "        self.coins = coins\n",
    "        self.position = 0\n",
    "        self.R = 0\n",
    "        self.Q = 0\n",
    "        self.states = []\n",
    "        self.coin_collected = False\n",
    "        self.terminate = False\n",
    "        \n",
    "    def plot_env(self):\n",
    "        cmap = plt.cm.colors.ListedColormap(['white', 'orange', 'red', 'blue', 'yellow'])\n",
    "        maze_plot = self.maze.copy()\n",
    "        maze_plot[self.target] = 2\n",
    "        maze_plot[self.start] = 3\n",
    "        maze_plot[self.coins] = 4\n",
    "        plt.imshow(maze_plot, cmap=cmap)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_env_position(self, position, timestep):\n",
    "        cmap = plt.cm.colors.ListedColormap(['white', 'orange', 'red', 'blue', 'yellow'])\n",
    "        maze_plot = self.maze.copy()\n",
    "        maze_plot[self.target] = 2\n",
    "        maze_plot[position] = 3\n",
    "        maze_plot[self.coins] = 4\n",
    "        plt.imshow(maze_plot, cmap=cmap)\n",
    "        plt.savefig(f'img/plot_{timestep:06d}.png', dpi=300)\n",
    "        plt.show()\n",
    "        plt.close() \n",
    "        \n",
    "    def create_r_matrix(self):\n",
    "        actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        num_states = self.maze.shape[0] * self.maze.shape[1]\n",
    "        R = np.full((num_states, 4), np.nan)\n",
    "\n",
    "        state_index = 0\n",
    "        for i in range(self.maze.shape[0]):\n",
    "            for j in range(self.maze.shape[1]):\n",
    "            # If the cell is not a wall\n",
    "                if self.maze[i, j] == 0:\n",
    "                    for index, action in enumerate(actions):\n",
    "                        new_position = (i + action[0], j + action[1])\n",
    "                        # If action leads to a valid state\n",
    "                        if (0 <= new_position[0] < self.maze.shape[0] and\n",
    "                            0 <= new_position[1] < self.maze.shape[1] and\n",
    "                            self.maze[new_position] == 0):\n",
    "                            # Calculate the state number for the new position\n",
    "                            # Set reward to 0\n",
    "                            R[state_index, index] = -5\n",
    "\n",
    "                            # If action leads to goal state set reward to 100\n",
    "                            if new_position == self.target:\n",
    "                                R[state_index, index] = 1000\n",
    "                            if new_position == self.coins:\n",
    "                                R[state_index, index] = 200\n",
    "                state_index += 1\n",
    "                            \n",
    "        self.R = R\n",
    "        print(self.R.shape)\n",
    "        return self.R\n",
    "    \n",
    "    def reward(self, state, action):\n",
    "        state = self.states[state]\n",
    "        x, y = state\n",
    "        if action == 0:  # up\n",
    "            x -= 1\n",
    "        elif action == 1:  # down\n",
    "            x += 1\n",
    "        elif action == 2:  # left\n",
    "            y -= 1\n",
    "        elif action == 3:  # right\n",
    "            y += 1\n",
    "        if x < 0 or x >= len(self.maze) or y < 0 or y >= len(self.maze[0]) or self.maze[x][y] == 1:\n",
    "            return -0.  # hit a wall (including edges wall?)\n",
    "        elif (x, y) == self.target:\n",
    "            print(\"Reached Target!\")\n",
    "            print((x,y))\n",
    "            \n",
    "            return 0 + int(self.coin_collected == True) # reached the target and bonus if collected coin\n",
    "        elif (x, y) == self.coins and not self.coin_collected:\n",
    "            print(\"DING DING DING\")\n",
    "            return 10\n",
    "        else:\n",
    "            return -0.001  # regular step\n",
    "        \n",
    "    def transition(self, state, action):\n",
    "        state_new = self.states[state]\n",
    "        x, y = state_new\n",
    "        if action == 0:  # up\n",
    "            x -= 1\n",
    "        elif action == 1:  # down\n",
    "            x += 1\n",
    "        elif action == 2:  # left\n",
    "            y -= 1\n",
    "        elif action == 3:  # right\n",
    "            y += 1\n",
    "\n",
    "        if x < 0 or x >= len(self.maze) or y < 0 or y >= len(self.maze[0]) or self.maze[x][y] == 1:\n",
    "#             self.terminate = True\n",
    "            return self.states.index(state_new)  # hit a wall, stay in the same state\n",
    "        else:\n",
    "            if (x, y) == self.coins and not self.coin_collected:\n",
    "                self.coin_collected = True\n",
    "                return 100 #specific index for coin\n",
    "            else:\n",
    "                if (x, y) == self.target:\n",
    "                    self.terminate = True\n",
    "                return self.states.index((x,y))  # move to the new state\n",
    "        \n",
    "    def done(self):\n",
    "        return self.terminate\n",
    "    \n",
    "    def create_q_matrix(self):\n",
    "        coord_to_index = []\n",
    "        for i in range(self.maze.shape[0]):\n",
    "            for j in range(self.maze.shape[1]):\n",
    "                coord_to_index.append((i,j))\n",
    "        coord_to_index.append(self.coins)\n",
    "        print(coord_to_index)\n",
    "                \n",
    "        num_states = self.maze.shape[0] * self.maze.shape[1] + 1\n",
    "        num_actions = 4\n",
    "        self.Q = np.zeros((num_states, num_actions))\n",
    "        print(self.Q.shape)\n",
    "        self.states = coord_to_index\n",
    "        return self.Q, coord_to_index\n",
    "\n",
    "maze = np.array([\n",
    "    [1, 0, 1, 1, 1, 1, 1, 0, 0, 1],\n",
    " [0, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
    " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    " [0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    " [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    " [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    " [1, 1, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    " [0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    " [1, 1, 1, 1, 0, 1, 0, 1, 1, 0],\n",
    " [0, 1, 0, 0, 1, 1, 1, 0, 0, 1]\n",
    "                ])\n",
    "# env = Maze_env((2,0),(0,8),(6,6), maze) \n",
    "env = Maze_env((2,0),(0,8),(7,5), maze) \n",
    "env.plot_env()\n",
    "# R = env.create_r_matrix()\n",
    "# print('R matrix: \\n\\n{}'.format(R))\n",
    "Q, coord_to_index = env.create_q_matrix()\n",
    "print('Q matrix: \\n\\n{}'.format(Q))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "406d55f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Q_learning:\n",
    "    \n",
    "    def __init__(self, alpha, gamma, epsilon, episodes, steps, env, states):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.temperature = 100.0\n",
    "        self.states = states\n",
    "\n",
    "#         self.R = env.R\n",
    "#         self.R_mod = self.R.copy()\n",
    "        self.Q = env.Q\n",
    "        self.episodes = episodes\n",
    "        self.steps = steps\n",
    "        self.start = env.start\n",
    "        self.target = self.states.index(env.target)\n",
    "        self.coins = env.coins\n",
    "        self.env = env\n",
    "        self.episodes_rewards = []\n",
    "        self.max_list_size = 10\n",
    "        self.list_rewards = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.threshold = 2\n",
    "        self.window_size = 4\n",
    "        self.current_average = 0\n",
    "        \n",
    "        print(\"Initial Q matrix is '{}'\".format(self.Q))\n",
    "\n",
    "    def plot_rewards(self):\n",
    "        plt.plot(self.episodes_rewards)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_Q_spec(self,coord):\n",
    "        print(q_learning.Q[self.states.index(coord)])\n",
    "        \n",
    "    def greedy_policy(self, state):\n",
    "#                 available_actions = np.where(~np.isnan(self.R_mod[s]))[0]\n",
    "#                 q_values = [self.Q[s,a] for a in available_actions]\n",
    "#                 best_actions = available_actions[np.where(q_values == np.max(q_values))[0]]\n",
    "        \n",
    "        available_actions = np.array([0,1,2,3])\n",
    "        q_values = [self.Q[state,a] for a in available_actions]\n",
    "        best_actions = available_actions[np.where(q_values == np.max(q_values))[0]]\n",
    "\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            a = np.random.choice(4)\n",
    "#                     a = np.random.choice(available_actions)\n",
    "        else:\n",
    "#                     a = np.argmax(self.Q[s,:])\n",
    "            a = np.random.choice(best_actions)\n",
    "        return a\n",
    "    \n",
    "    def softmax_policy(self, state, temperature = 1.0):\n",
    "        available_actions = np.array([0,1,2,3])\n",
    "        q_values = np.array([self.Q[state,a] for a in available_actions])\n",
    "        max_q_value = np.max(q_values)\n",
    "        exp_values = np.exp((q_values - max_q_value) / temperature)\n",
    "        action_probs = exp_values / np.sum(exp_values)\n",
    "\n",
    "        # Sample an action based on the probabilities\n",
    "        selected_action = np.random.choice(len(action_probs), p=action_probs)\n",
    "        return selected_action\n",
    "        \n",
    "    def train(self):\n",
    "        print(self.states)\n",
    "        print(\"Starting taget is '{}'\".format(self.target))\n",
    "        for episode in range(self.episodes):\n",
    "            s = self.states.index(self.start)\n",
    "            print(\"Starting state is '{}'\".format(s))\n",
    "            episode_reward = 0\n",
    "            env.coin_collected = False\n",
    "            env.terminate = False\n",
    "#             self.R_mod = self.R\n",
    "            for timestep in range(self.steps):\n",
    "\n",
    "                # Epsilon-greedy action choice\n",
    "#                 a = self.greedy_policy(s)\n",
    "                a = self.softmax_policy(s, self.temperature)\n",
    "\n",
    "                # Environment updating\n",
    "                r = env.reward(s, a)\n",
    "#                 r = self.R_mod[s,a]\n",
    "                episode_reward += r\n",
    "                new_s = env.transition(s, a)\n",
    "                # Doubts coordinates to Q system?\n",
    "                # Q value updating\n",
    "#                 print(new_s)\n",
    "                self.Q[s,a] = self.Q[s,a] + self.alpha * ( r + self.gamma * np.max(self.Q[new_s,:]) - self.Q[s,a])\n",
    "\n",
    "                if env.done():\n",
    "                    break\n",
    "                s = new_s\n",
    "            \n",
    "            self.episodes_rewards.append(episode_reward)\n",
    "            \n",
    "            self.list_rewards.append(episode_reward)\n",
    "            if len(self.list_rewards) > self.max_list_size:\n",
    "                self.list_rewards.pop(0)\n",
    "            window = self.list_rewards[-self.window_size:]\n",
    "            window_average = sum(window) / self.window_size\n",
    "#             if abs(self.current_average - window_average) < self.threshold:\n",
    "#                 print(f\"Average exceeded threshold at episode {episode}. STOPPING!\")\n",
    "#                 break \n",
    "            self.current_average = window_average\n",
    "\n",
    "            if episode % 2 == 0:\n",
    "                print('Episode {} finished. Episode Reward {}. Timesteps {}. Average {}'.format(episode,episode_reward,timestep, window_average))\n",
    "            self.epsilon = max(self.epsilon*0.999,0.01)\n",
    "            self.temperature = max(self.temperature*0.998,0.01)\n",
    "\n",
    "            print(self.temperature)\n",
    "            \n",
    "    def create_video(self):\n",
    "        image_folder = 'img'  # Directory containing your saved plot images\n",
    "        video_name = 'video_agent.mp4'\n",
    "\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 1, (width, height))\n",
    "\n",
    "        for image in images:\n",
    "            video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "        \n",
    "    \n",
    "    def test(self, limit):\n",
    "\n",
    "        s = self.states.index(self.start)\n",
    "        print(\"Starting state is '{}'\".format(s))\n",
    "        episode_reward = 0\n",
    "        env.coin_collected = False\n",
    "        for timestep in range(limit):\n",
    "            self.env.plot_env_position(self.states[s], timestep)\n",
    "            print(self.Q[s])\n",
    "            a = np.argmax(self.Q[s])\n",
    "            print(a)\n",
    "\n",
    "            # Environment updating\n",
    "            r = env.reward(s, a)\n",
    "            print(r)\n",
    "            episode_reward += r\n",
    "            temp_new_s = env.transition(s, a)\n",
    "#             new_s = self.states.index(temp_new_s)\n",
    "\n",
    "            if temp_new_s == self.target:\n",
    "                self.env.plot_env_position(self.states[temp_new_s], timestep)\n",
    "                break\n",
    "            s = temp_new_s\n",
    "        print('Episode Reward {}.Q matrix values:\\n{}'.format(episode_reward,self.Q.round(1)))\n",
    "        self.create_video()\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876c893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q matrix is '[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]'\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (7, 0), (7, 1), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (8, 0), (8, 1), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7), (8, 8), (8, 9), (9, 0), (9, 1), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9), (7, 5)]\n",
      "Starting taget is '8'\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 0 finished. Episode Reward 10.514000000000117. Timesteps 773. Average 2.628500000000029\n",
      "99.8\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "99.6004\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 2 finished. Episode Reward 10.560000000000183. Timesteps 662. Average 7.915500000000099\n",
      "99.4011992\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "99.20239680159999\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 4 finished. Episode Reward 10.282000000000364. Timesteps 1096. Average 10.516000000000203\n",
      "99.00399200799679\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "98.8059840239808\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 6 finished. Episode Reward 10.530000000000193. Timesteps 749. Average 7.8532500000001795\n",
      "98.60837205593283\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "98.41115531182096\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 8 finished. Episode Reward -0.18500000000000014. Timesteps 360. Average 5.201500000000098\n",
      "98.21433300119732\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "98.01790433519493\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 10 finished. Episode Reward 8.833000000000498. Timesteps 1999. Average 7.46200000000019\n",
      "97.82186852652454\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "97.6262247894715\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 12 finished. Episode Reward 10.452000000000288. Timesteps 931. Average 10.131250000000223\n",
      "97.43097233989255\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "97.23611039521276\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 14 finished. Episode Reward 10.702000000000032. Timesteps 523. Average 7.865750000000089\n",
      "97.04163817442233\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "96.84755489807348\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 16 finished. Episode Reward 10.650000000000055. Timesteps 598. Average 7.763750000000146\n",
      "96.65385978827733\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "96.46055206870078\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 18 finished. Episode Reward 10.708000000000082. Timesteps 510. Average 10.365000000000228\n",
      "96.26763096456338\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "96.07509570263426\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 20 finished. Episode Reward 10.446000000000197. Timesteps 989. Average 10.022250000000284\n",
      "95.88294551122898\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "95.69117962020653\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 22 finished. Episode Reward 10.400000000000263. Timesteps 1023. Average 7.2865000000002595\n",
      "95.49979726096612\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "95.30879766644419\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 24 finished. Episode Reward -0.059000000000000045. Timesteps 118. Average 5.022500000000137\n",
      "95.1181800711113\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "94.92794371096907\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 26 finished. Episode Reward 8.772000000000615. Timesteps 1999. Average 4.688500000000225\n",
      "94.73808782354713\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "94.54861164790003\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 28 finished. Episode Reward 10.876000000000031. Timesteps 243. Average 7.447750000000253\n",
      "94.35951442460423\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "94.17079539575502\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 30 finished. Episode Reward 10.560000000000207. Timesteps 803. Average 10.616500000000189\n",
      "93.98245380496351\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "93.79448889735359\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 32 finished. Episode Reward 8.744000000000405. Timesteps 1999. Average 10.111500000000257\n",
      "93.60689991955888\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "93.41968611971977\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 34 finished. Episode Reward 10.646000000000122. Timesteps 590. Average 7.435750000000199\n",
      "93.23284674748034\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "93.04638105398537\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 36 finished. Episode Reward 10.450000000000223. Timesteps 1047. Average 7.768250000000204\n",
      "92.8602882918774\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "92.67456771529363\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 38 finished. Episode Reward 8.756000000000594. Timesteps 1999. Average 9.501000000000474\n",
      "92.48921857986305\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "92.30424014270332\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 40 finished. Episode Reward 10.472000000000149. Timesteps 919. Average 9.187500000000494\n",
      "92.11963166241792\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "91.93539239909308\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 42 finished. Episode Reward 10.022000000000242. Timesteps 1624. Average 9.491250000000425\n",
      "91.75152161429489\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "91.5680185710663\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 44 finished. Episode Reward 8.82300000000057. Timesteps 1999. Average 9.378000000000482\n",
      "91.38488253392417\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "91.20211276885632\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 46 finished. Episode Reward 10.706000000000136. Timesteps 478. Average 9.554000000000457\n",
      "91.01970854331861\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "90.83766912623197\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 48 finished. Episode Reward 10.216000000000372. Timesteps 1217. Average 9.98525000000039\n",
      "90.65599378797951\n",
      "Starting state is '20'\n",
      "DING DING DING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.47468180040356\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 50 finished. Episode Reward 8.77000000000059. Timesteps 1999. Average 9.506000000000473\n",
      "90.29373243680276\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "90.11314497192915\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 52 finished. Episode Reward 10.292000000000254. Timesteps 1195. Average 9.49150000000046\n",
      "89.93291868198529\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "89.75305284462131\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 54 finished. Episode Reward 8.776000000000622. Timesteps 1999. Average 9.91450000000037\n",
      "89.57354673893207\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "89.3943996454542\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 56 finished. Episode Reward 10.352000000000011. Timesteps 1126. Average 9.585250000000354\n",
      "89.21561084616329\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "89.03717962447097\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 58 finished. Episode Reward 8.742000000000555. Timesteps 1999. Average 9.482250000000413\n",
      "88.85910526522203\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "88.68138705469158\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 60 finished. Episode Reward 8.761000000000564. Timesteps 1999. Average 9.09250000000055\n",
      "88.5040242805822\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "88.32701623202104\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 62 finished. Episode Reward 8.806000000000592. Timesteps 1999. Average 8.808000000000595\n",
      "88.150362199557\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "87.97406147515788\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 64 finished. Episode Reward 8.79100000000064. Timesteps 1999. Average 9.236250000000505\n",
      "87.79811335220757\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "87.62251712550315\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 66 finished. Episode Reward 8.711000000000585. Timesteps 1999. Average 6.9567500000003495\n",
      "87.44727209125215\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "87.27237754706964\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 68 finished. Episode Reward 9.914000000000572. Timesteps 1729. Average 7.110000000000417\n",
      "87.09783279197549\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "86.92363712639154\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 70 finished. Episode Reward 10.132000000000215. Timesteps 1414. Average 9.689000000000432\n",
      "86.74978985213876\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "86.57629027243448\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 72 finished. Episode Reward 8.85000000000039. Timesteps 1999. Average 6.884250000000257\n",
      "86.40313769188961\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "86.23033141650583\n",
      "Starting state is '20'\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 74 finished. Episode Reward -0.11100000000000008. Timesteps 213. Average 4.343500000000252\n",
      "86.05787075367282\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "85.88575501216548\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 76 finished. Episode Reward 8.789000000000529. Timesteps 1999. Average 6.57250000000043\n",
      "85.71398350214115\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "85.54255553513687\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 78 finished. Episode Reward 8.723000000000424. Timesteps 1999. Average 9.023500000000539\n",
      "85.3714704240666\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "85.20072748321847\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 80 finished. Episode Reward 8.796000000000458. Timesteps 1999. Average 9.050750000000463\n",
      "85.03032602825203\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "84.86026537619553\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 82 finished. Episode Reward 9.86600000000043. Timesteps 1903. Average 9.085750000000449\n",
      "84.69054484544314\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "84.52116375575226\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 84 finished. Episode Reward 8.811000000000638. Timesteps 1999. Average 9.05275000000057\n",
      "84.35212142824075\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "84.18341718538427\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 86 finished. Episode Reward 10.116000000000446. Timesteps 1603. Average 9.102750000000595\n",
      "84.0150503510135\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "83.84702025031147\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 88 finished. Episode Reward 8.74100000000028. Timesteps 1999. Average 9.07950000000049\n",
      "83.67932620981085\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "83.51196755739123\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 90 finished. Episode Reward 8.734000000000645. Timesteps 1999. Average 9.180250000000424\n",
      "83.34494362227645\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "83.17825373503189\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 92 finished. Episode Reward 8.735000000000525. Timesteps 1999. Average 9.175500000000474\n",
      "83.01189722756182\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "82.84587343310669\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 94 finished. Episode Reward 8.81300000000052. Timesteps 1999. Average 8.76350000000055\n",
      "82.68018168624047\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "82.51482132286799\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 96 finished. Episode Reward 8.747000000000655. Timesteps 1999. Average 8.76650000000062\n",
      "82.34979168022225\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "82.18509209686181\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Reached Target!\n",
      "(0, 8)\n",
      "Episode 98 finished. Episode Reward 10.328000000000257. Timesteps 1116. Average 9.15500000000054\n",
      "82.02072191266808\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "81.85668046884274\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 100 finished. Episode Reward 8.71500000000057. Timesteps 1999. Average 9.163000000000482\n",
      "81.69296710790505\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "81.52958117368924\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 102 finished. Episode Reward 8.749000000000539. Timesteps 1999. Average 8.741250000000537\n",
      "81.36652201134186\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "81.20378896731917\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 104 finished. Episode Reward 8.733000000000615. Timesteps 1999. Average 8.730000000000572\n",
      "81.04138138938453\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "80.87929862660576\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 106 finished. Episode Reward 8.759000000000643. Timesteps 1999. Average 8.764500000000602\n",
      "80.71754002935255\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "80.55610494929384\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 108 finished. Episode Reward 8.854000000000605. Timesteps 1999. Average 8.820500000000527\n",
      "80.39499273939525\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "80.23420275391646\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 110 finished. Episode Reward 8.723000000000692. Timesteps 1999. Average 8.792500000000565\n",
      "80.07373434840864\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "79.91358687971181\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 112 finished. Episode Reward 8.78500000000055. Timesteps 1999. Average 8.772250000000582\n",
      "79.75375970595239\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "79.59425218654049\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 114 finished. Episode Reward 8.803000000000496. Timesteps 1999. Average 8.79150000000053\n",
      "79.43506368216741\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "79.27619355480307\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 116 finished. Episode Reward 8.763000000000652. Timesteps 1999. Average 8.770000000000598\n",
      "79.11764116769346\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "78.95940588535808\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 118 finished. Episode Reward 8.742000000000555. Timesteps 1999. Average 8.744250000000614\n",
      "78.80148707358737\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "78.64388409944019\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 120 finished. Episode Reward 8.932000000000418. Timesteps 1999. Average 8.78100000000056\n",
      "78.4865963312413\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "78.32962313857882\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 122 finished. Episode Reward 8.723000000000612. Timesteps 1999. Average 8.812000000000568\n",
      "78.17296389230167\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "78.01661796451707\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 124 finished. Episode Reward 8.7180000000006. Timesteps 1999. Average 8.755000000000576\n",
      "77.86058472858804\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "77.70486355913086\n",
      "Starting state is '20'\n",
      "DING DING DING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 126 finished. Episode Reward 8.717000000000686. Timesteps 1999. Average 8.739750000000582\n",
      "77.54945383201259\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "77.39435492434856\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 128 finished. Episode Reward 8.81000000000052. Timesteps 1999. Average 8.77425000000059\n",
      "77.23956621449986\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "77.08508708207086\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 130 finished. Episode Reward 8.749000000000636. Timesteps 1999. Average 8.782750000000597\n",
      "76.93091690790672\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "76.77705507409091\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 132 finished. Episode Reward 8.74700000000067. Timesteps 1999. Average 8.771750000000642\n",
      "76.62350096394273\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "76.47025396201485\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 134 finished. Episode Reward 8.773000000000577. Timesteps 1999. Average 8.785750000000585\n",
      "76.31731345409082\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "76.16467882718264\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 136 finished. Episode Reward 8.84400000000062. Timesteps 1999. Average 8.800500000000548\n",
      "76.01234946952827\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "75.86032477058922\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 138 finished. Episode Reward 8.808000000000607. Timesteps 1999. Average 8.7902500000006\n",
      "75.70860412104804\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "75.55718691280595\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 140 finished. Episode Reward 8.75600000000058. Timesteps 1999. Average 8.751250000000624\n",
      "75.40607253898034\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "75.25526039390238\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 142 finished. Episode Reward 8.747000000000504. Timesteps 1999. Average 8.736000000000603\n",
      "75.10474987311457\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "74.95454037336835\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 144 finished. Episode Reward 8.682000000000677. Timesteps 1999. Average 8.7462500000006\n",
      "74.80463129262161\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "74.65502203003636\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 146 finished. Episode Reward 8.751000000000664. Timesteps 1999. Average 8.717250000000645\n",
      "74.50571198597629\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "74.35670056200433\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 148 finished. Episode Reward 8.747000000000671. Timesteps 1999. Average 8.744750000000616\n",
      "74.20798716088032\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "74.05957118655856\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 150 finished. Episode Reward 8.727000000000608. Timesteps 1999. Average 8.73700000000061\n",
      "73.91145204418544\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "73.76362914009707\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 152 finished. Episode Reward 8.705000000000481. Timesteps 1999. Average 8.704750000000585\n",
      "73.61610188181687\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "73.46886967805324\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 154 finished. Episode Reward 8.76600000000063. Timesteps 1999. Average 8.749000000000564\n",
      "73.32193193869713\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "73.17528807481973\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 156 finished. Episode Reward 8.746000000000608. Timesteps 1999. Average 8.759000000000597\n",
      "73.02893749867009\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "72.88287962367275\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 158 finished. Episode Reward 8.771000000000507. Timesteps 1999. Average 8.745750000000568\n",
      "72.73711386442541\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "72.59163963669656\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 160 finished. Episode Reward 8.811000000000604. Timesteps 1999. Average 8.756250000000579\n",
      "72.44645635742316\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "72.30156344470831\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 162 finished. Episode Reward 8.697000000000621. Timesteps 1999. Average 8.747000000000613\n",
      "72.15696031781889\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "72.01264639718325\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 164 finished. Episode Reward 8.787000000000601. Timesteps 1999. Average 8.745000000000598\n",
      "71.86862110438888\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "71.7248838621801\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 166 finished. Episode Reward 8.78200000000064. Timesteps 1999. Average 8.77325000000061\n",
      "71.58143409445574\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "71.43827122626683\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 168 finished. Episode Reward 8.762000000000658. Timesteps 1999. Average 8.761000000000653\n",
      "71.2953946838143\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "71.15280389444666\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 170 finished. Episode Reward 8.722000000000618. Timesteps 1999. Average 8.720000000000665\n",
      "71.01049828665776\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "70.86847729008444\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 172 finished. Episode Reward 8.780000000000559. Timesteps 1999. Average 8.750000000000576\n",
      "70.72674033550427\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "70.58528685483327\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 174 finished. Episode Reward 8.73500000000041. Timesteps 1999. Average 8.767250000000512\n",
      "70.4441162811236\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "70.30322804856135\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 176 finished. Episode Reward 8.80100000000059. Timesteps 1999. Average 8.771750000000551\n",
      "70.16262159246423\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "70.0222963492793\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 178 finished. Episode Reward 8.737000000000513. Timesteps 1999. Average 8.786500000000533\n",
      "69.88225175658074\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "69.74248725306758\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 180 finished. Episode Reward 8.663000000000599. Timesteps 1999. Average 8.733250000000561\n",
      "69.60300227856145\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "69.46379627400432\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 182 finished. Episode Reward 8.814000000000581. Timesteps 1999. Average 8.737250000000614\n",
      "69.32486868145631\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "69.1862189440934\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 184 finished. Episode Reward 8.80600000000062. Timesteps 1999. Average 8.782500000000606\n",
      "69.0478465062052\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "68.90975081319279\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 186 finished. Episode Reward 8.782000000000528. Timesteps 1999. Average 8.791250000000588\n",
      "68.7719313115664\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "68.63438744894327\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 188 finished. Episode Reward 8.719000000000669. Timesteps 1999. Average 8.776000000000606\n",
      "68.49711867404538\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "68.36012443669729\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 190 finished. Episode Reward 8.844000000000618. Timesteps 1999. Average 8.794000000000617\n",
      "68.2234041878239\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "68.08695737944825\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 192 finished. Episode Reward 8.7190000000007. Timesteps 1999. Average 8.798500000000587\n",
      "67.95078346468935\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "67.81488189775997\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 194 finished. Episode Reward 8.852000000000567. Timesteps 1999. Average 8.80175000000059\n",
      "67.67925213396445\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "67.54389362969653\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 196 finished. Episode Reward 8.822000000000616. Timesteps 1999. Average 8.81125000000059\n",
      "67.40880584243713\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "67.27398823075225\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 198 finished. Episode Reward 8.84700000000039. Timesteps 1999. Average 8.807500000000516\n",
      "67.13944025429075\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "67.00516137378217\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 200 finished. Episode Reward 8.761000000000557. Timesteps 1999. Average 8.8112500000005\n",
      "66.8711510510346\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "66.73740874893254\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 202 finished. Episode Reward 8.82300000000063. Timesteps 1999. Average 8.790000000000589\n",
      "66.60393393143467\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "66.4707260635718\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 204 finished. Episode Reward 8.764000000000642. Timesteps 1999. Average 8.759250000000634\n",
      "66.33778461144466\n",
      "Starting state is '20'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DING DING DING\n",
      "66.20510904222178\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 206 finished. Episode Reward 8.822000000000626. Timesteps 1999. Average 8.796000000000564\n",
      "66.07269882413733\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "65.94055342648906\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 208 finished. Episode Reward 8.804000000000356. Timesteps 1999. Average 8.831000000000486\n",
      "65.80867231963609\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "65.67705497499682\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 210 finished. Episode Reward 8.78900000000056. Timesteps 1999. Average 8.81000000000045\n",
      "65.54570086504683\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "65.41460946331674\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 212 finished. Episode Reward 8.797000000000583. Timesteps 1999. Average 8.79600000000051\n",
      "65.2837802443901\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "65.15321268390132\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 214 finished. Episode Reward 8.764000000000626. Timesteps 1999. Average 8.754750000000591\n",
      "65.02290625853351\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "64.89286044601644\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 216 finished. Episode Reward 8.777000000000562. Timesteps 1999. Average 8.756500000000507\n",
      "64.76307472512441\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "64.63354857567417\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 218 finished. Episode Reward 8.701000000000684. Timesteps 1999. Average 8.750750000000535\n",
      "64.50428147852283\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "64.37527291556579\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 220 finished. Episode Reward 8.726000000000676. Timesteps 1999. Average 8.729000000000639\n",
      "64.24652236973465\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "64.11802932499518\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 222 finished. Episode Reward 8.785000000000633. Timesteps 1999. Average 8.74825000000061\n",
      "63.98979326634519\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "63.8618136798125\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 224 finished. Episode Reward 8.803000000000583. Timesteps 1999. Average 8.750500000000596\n",
      "63.73409005245288\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "63.60662187234797\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 226 finished. Episode Reward 8.779000000000602. Timesteps 1999. Average 8.760250000000616\n",
      "63.479408628603274\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "63.35244981134607\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 228 finished. Episode Reward 8.79100000000063. Timesteps 1999. Average 8.777750000000621\n",
      "63.225744911723375\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "63.09929342189993\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 230 finished. Episode Reward 8.7710000000006. Timesteps 1999. Average 8.786500000000624\n",
      "62.97309483505613\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "62.84714864538602\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 232 finished. Episode Reward 8.767000000000527. Timesteps 1999. Average 8.790500000000577\n",
      "62.72145434809525\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "62.59601143939906\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 234 finished. Episode Reward 8.711000000000663. Timesteps 1999. Average 8.758250000000595\n",
      "62.47081941652026\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "62.345877777687214\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 236 finished. Episode Reward 8.724000000000606. Timesteps 1999. Average 8.718750000000647\n",
      "62.22118602213184\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "62.096743650087575\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 238 finished. Episode Reward 8.73100000000061. Timesteps 1999. Average 8.739250000000602\n",
      "61.9725501627874\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "61.84860506246182\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 240 finished. Episode Reward 8.718000000000666. Timesteps 1999. Average 8.764000000000587\n",
      "61.7249078523369\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "61.60145803663222\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 242 finished. Episode Reward 8.776000000000518. Timesteps 1999. Average 8.75225000000061\n",
      "61.478255120558956\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "61.35529861031784\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 244 finished. Episode Reward 8.834000000000545. Timesteps 1999. Average 8.759500000000601\n",
      "61.2325880130972\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "61.110122837071\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 246 finished. Episode Reward 8.717000000000677. Timesteps 1999. Average 8.750500000000635\n",
      "60.98790259139686\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "60.86592678621407\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 248 finished. Episode Reward 8.745000000000614. Timesteps 1999. Average 8.738750000000644\n",
      "60.74419493264164\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "60.622706542776356\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 250 finished. Episode Reward 8.810000000000553. Timesteps 1999. Average 8.780000000000573\n",
      "60.5014611296908\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "60.380458207431424\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 252 finished. Episode Reward 8.738000000000694. Timesteps 1999. Average 8.78800000000055\n",
      "60.25969729101656\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "60.139177896434525\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 254 finished. Episode Reward 8.728000000000677. Timesteps 1999. Average 8.767250000000566\n",
      "60.018899540641655\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "59.898861741560374\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 256 finished. Episode Reward 8.705000000000597. Timesteps 1999. Average 8.751250000000596\n",
      "59.77906401807725\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "59.659505890041096\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 258 finished. Episode Reward 8.794000000000615. Timesteps 1999. Average 8.760250000000621\n",
      "59.54018687826101\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "59.421106504504486\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 260 finished. Episode Reward 8.740000000000563. Timesteps 1999. Average 8.74800000000062\n",
      "59.302264291495476\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "59.183659762912484\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 262 finished. Episode Reward 8.8100000000005. Timesteps 1999. Average 8.755500000000577\n",
      "59.06529244338666\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "58.94716185849989\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 264 finished. Episode Reward 8.743000000000556. Timesteps 1999. Average 8.782750000000568\n",
      "58.829267534782886\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "58.71160899971332\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 266 finished. Episode Reward 8.741000000000529. Timesteps 1999. Average 8.76650000000058\n",
      "58.5941857817139\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "58.47699741015047\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 268 finished. Episode Reward 8.748000000000566. Timesteps 1999. Average 8.765250000000574\n",
      "58.36004341533017\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "58.24332332849951\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 270 finished. Episode Reward 8.737000000000245. Timesteps 1999. Average 8.748000000000513\n",
      "58.126836681842505\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "58.01058300847882\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 272 finished. Episode Reward 8.768000000000624. Timesteps 1999. Average 8.737250000000504\n",
      "57.89456184246186\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "57.778772718776935\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 274 finished. Episode Reward 8.698000000000679. Timesteps 1999. Average 8.720250000000597\n",
      "57.66321517333938\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "57.547888742992704\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 276 finished. Episode Reward 8.716000000000477. Timesteps 1999. Average 8.712750000000586\n",
      "57.43279296550672\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "57.31792737957571\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 278 finished. Episode Reward 8.74300000000055. Timesteps 1999. Average 8.718000000000568\n",
      "57.20329152481656\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "57.08888494176692\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 280 finished. Episode Reward 8.712000000000634. Timesteps 1999. Average 8.703750000000623\n",
      "56.97470717188339\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "56.86075775753962\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 282 finished. Episode Reward 8.78400000000049. Timesteps 1999. Average 8.741750000000586\n",
      "56.74703624202454\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "56.63354216954049\n",
      "Starting state is '20'\n",
      "DING DING DING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 284 finished. Episode Reward 8.749000000000574. Timesteps 1999. Average 8.777500000000556\n",
      "56.52027508520141\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "56.40723453503101\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 286 finished. Episode Reward 8.726000000000647. Timesteps 1999. Average 8.738000000000634\n",
      "56.29442006596095\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "56.18183122582903\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 288 finished. Episode Reward 8.75300000000066. Timesteps 1999. Average 8.742500000000652\n",
      "56.06946756337737\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "55.957328628250615\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 290 finished. Episode Reward 8.817000000000553. Timesteps 1999. Average 8.78800000000062\n",
      "55.845413970994116\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "55.733723143052124\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 292 finished. Episode Reward 8.786000000000422. Timesteps 1999. Average 8.785250000000524\n",
      "55.62225569676602\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "55.51101118537249\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 294 finished. Episode Reward 8.752000000000665. Timesteps 1999. Average 8.747250000000557\n",
      "55.39998916300174\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "55.289189184675735\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 296 finished. Episode Reward 8.667000000000703. Timesteps 1999. Average 8.710750000000676\n",
      "55.17861080630638\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "55.06825358469377\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 298 finished. Episode Reward 8.803000000000393. Timesteps 1999. Average 8.756750000000585\n",
      "54.958117077524385\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "54.848200843369334\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 300 finished. Episode Reward 8.775000000000603. Timesteps 1999. Average 8.785750000000547\n",
      "54.73850444168259\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "54.62902743279923\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 302 finished. Episode Reward 8.691000000000694. Timesteps 1999. Average 8.751750000000625\n",
      "54.51976937793363\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "54.41072983917776\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 304 finished. Episode Reward 8.77900000000065. Timesteps 1999. Average 8.752000000000638\n",
      "54.30190837949941\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "54.19330456274041\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 306 finished. Episode Reward 8.748000000000534. Timesteps 1999. Average 8.758000000000585\n",
      "54.08491795361493\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "53.97674811770769\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 308 finished. Episode Reward 8.751000000000607. Timesteps 1999. Average 8.75825000000055\n",
      "53.868794621472276\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "53.76105703222933\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 310 finished. Episode Reward 8.69600000000062. Timesteps 1999. Average 8.76250000000058\n",
      "53.65353491816487\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "53.54622784832854\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 312 finished. Episode Reward 8.714000000000647. Timesteps 1999. Average 8.754750000000612\n",
      "53.43913539263188\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "53.33225712184662\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 314 finished. Episode Reward 8.856000000000556. Timesteps 1999. Average 8.76900000000058\n",
      "53.22559260760292\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "53.11914142238771\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 316 finished. Episode Reward 8.750000000000627. Timesteps 1999. Average 8.791250000000547\n",
      "53.012903139542935\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "52.90687733326385\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 318 finished. Episode Reward 8.74700000000062. Timesteps 1999. Average 8.771750000000576\n",
      "52.80106357859732\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "52.695461451440124\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 320 finished. Episode Reward 8.747000000000593. Timesteps 1999. Average 8.7410000000006\n",
      "52.59007052853725\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "52.48489038748017\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 322 finished. Episode Reward 8.755000000000631. Timesteps 1999. Average 8.719250000000613\n",
      "52.37992060670521\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "52.275160765491805\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 324 finished. Episode Reward 8.765000000000601. Timesteps 1999. Average 8.73025000000062\n",
      "52.17061044396082\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "52.066269223072894\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 326 finished. Episode Reward 8.731000000000671. Timesteps 1999. Average 8.733250000000647\n",
      "51.96213668462675\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "51.8582124112575\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 328 finished. Episode Reward 8.79200000000039. Timesteps 1999. Average 8.752250000000583\n",
      "51.75449598643498\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "51.65098699446211\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 330 finished. Episode Reward 8.71900000000067. Timesteps 1999. Average 8.762750000000576\n",
      "51.54768502047318\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "51.444589650432235\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 332 finished. Episode Reward 8.81900000000061. Timesteps 1999. Average 8.774750000000573\n",
      "51.34170047113137\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "51.23901707018911\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 334 finished. Episode Reward 8.727000000000663. Timesteps 1999. Average 8.784000000000512\n",
      "51.13653903604873\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "51.034265957976636\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 336 finished. Episode Reward 8.811000000000611. Timesteps 1999. Average 8.764000000000586\n",
      "50.93219742606068\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "50.83033303120856\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 338 finished. Episode Reward 8.805000000000643. Timesteps 1999. Average 8.760000000000641\n",
      "50.728672365146146\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "50.62721502041585\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 340 finished. Episode Reward 8.74200000000068. Timesteps 1999. Average 8.748750000000651\n",
      "50.52596059037502\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "50.424908669194274\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 342 finished. Episode Reward 8.755000000000672. Timesteps 1999. Average 8.758000000000637\n",
      "50.32405885185589\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "50.223410734152175\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 344 finished. Episode Reward 8.683000000000591. Timesteps 1999. Average 8.779250000000582\n",
      "50.12296391268387\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "50.0227179848585\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 346 finished. Episode Reward 8.730000000000603. Timesteps 1999. Average 8.767250000000576\n",
      "49.922672548888784\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "49.82282720379101\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 348 finished. Episode Reward 8.70400000000065. Timesteps 1999. Average 8.728500000000622\n",
      "49.723181549383426\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "49.62373518628466\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 350 finished. Episode Reward 8.71600000000064. Timesteps 1999. Average 8.718250000000637\n",
      "49.524487715912095\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "49.42543874048027\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 352 finished. Episode Reward 8.703000000000603. Timesteps 1999. Average 8.733250000000556\n",
      "49.326587862999304\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "49.227934687273304\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 354 finished. Episode Reward 8.732000000000687. Timesteps 1999. Average 8.738500000000515\n",
      "49.12947881789876\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "49.03121986026296\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 356 finished. Episode Reward 8.76100000000065. Timesteps 1999. Average 8.754000000000595\n",
      "48.93315742054243\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "48.835291105701344\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 358 finished. Episode Reward 8.770000000000557. Timesteps 1999. Average 8.75450000000063\n",
      "48.737620523489944\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "48.640145282442965\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 360 finished. Episode Reward 8.83300000000042. Timesteps 1999. Average 8.764500000000575\n",
      "48.542864991878076\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "48.44577926189432\n",
      "Starting state is '20'\n",
      "DING DING DING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 362 finished. Episode Reward 8.744000000000664. Timesteps 1999. Average 8.786250000000539\n",
      "48.348887703370536\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "48.2521899279638\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 364 finished. Episode Reward 8.742000000000608. Timesteps 1999. Average 8.761000000000513\n",
      "48.15568554810787\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "48.059374177011655\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 366 finished. Episode Reward 8.728000000000442. Timesteps 1999. Average 8.76625000000045\n",
      "47.96325542865763\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "47.867328917800315\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 368 finished. Episode Reward 8.729000000000685. Timesteps 1999. Average 8.76050000000053\n",
      "47.771594259964715\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "47.67605107144479\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 370 finished. Episode Reward 8.753000000000517. Timesteps 1999. Average 8.73000000000056\n",
      "47.5806989693019\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "47.485537571363295\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 372 finished. Episode Reward 8.757000000000536. Timesteps 1999. Average 8.735250000000521\n",
      "47.39056649622057\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "47.295785363228134\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 374 finished. Episode Reward 8.792000000000622. Timesteps 1999. Average 8.757000000000591\n",
      "47.20119379250168\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "47.10679140491667\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 376 finished. Episode Reward 8.833000000000581. Timesteps 1999. Average 8.790000000000592\n",
      "47.012577822106834\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "46.918552666462624\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 378 finished. Episode Reward 8.76500000000054. Timesteps 1999. Average 8.775250000000575\n",
      "46.8247155611297\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "46.73106613000744\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 380 finished. Episode Reward 8.802000000000534. Timesteps 1999. Average 8.754500000000592\n",
      "46.637603997747426\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "46.54432878975193\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 382 finished. Episode Reward 8.776000000000648. Timesteps 1999. Average 8.769000000000606\n",
      "46.45124013217242\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "46.35833765190808\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 384 finished. Episode Reward 8.853000000000552. Timesteps 1999. Average 8.798750000000599\n",
      "46.26562097660426\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "46.17308973465105\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 386 finished. Episode Reward 8.775000000000656. Timesteps 1999. Average 8.813750000000589\n",
      "46.08074355518175\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.98858206807138\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 388 finished. Episode Reward 8.813000000000592. Timesteps 1999. Average 8.795000000000595\n",
      "45.89660490393524\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.80481169412737\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 390 finished. Episode Reward 8.710000000000582. Timesteps 1999. Average 8.758500000000605\n",
      "45.71320207073912\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.62177566659764\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 392 finished. Episode Reward 8.73600000000057. Timesteps 1999. Average 8.738250000000615\n",
      "45.53053211526445\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.43947105103392\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 394 finished. Episode Reward 8.761000000000582. Timesteps 1999. Average 8.749750000000606\n",
      "45.348592108931854\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.25789492471399\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 396 finished. Episode Reward 8.78400000000066. Timesteps 1999. Average 8.766000000000624\n",
      "45.16737913486456\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "45.077044376594834\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 398 finished. Episode Reward 8.699000000000638. Timesteps 1999. Average 8.75525000000059\n",
      "44.986890287841646\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.89691650726596\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 400 finished. Episode Reward 8.659000000000713. Timesteps 1999. Average 8.734000000000586\n",
      "44.80712267425143\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.71750842890293\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 402 finished. Episode Reward 8.742000000000655. Timesteps 1999. Average 8.755500000000614\n",
      "44.628073412045126\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.538817265221034\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 404 finished. Episode Reward 8.811000000000623. Timesteps 1999. Average 8.8127500000006\n",
      "44.449739630690594\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.360840151429215\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 406 finished. Episode Reward 8.721000000000664. Timesteps 1999. Average 8.797250000000584\n",
      "44.272118471126355\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.1835742341841\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 408 finished. Episode Reward 8.755000000000662. Timesteps 1999. Average 8.742500000000618\n",
      "44.09520708571573\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "44.0070166715443\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 410 finished. Episode Reward 8.701000000000699. Timesteps 1999. Average 8.729500000000616\n",
      "43.91900263820121\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "43.83116463292481\n",
      "Starting state is '20'\n",
      "DING DING DING\n",
      "Episode 412 finished. Episode Reward 8.7730000000006. Timesteps 1999. Average 8.73225000000059\n",
      "43.743502303658964\n",
      "Starting state is '20'\n",
      "DING DING DING\n"
     ]
    }
   ],
   "source": [
    "q_learning = Q_learning(1, 0.999, 1, 5000, 2000, env, coord_to_index)\n",
    "q_learning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b61fe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_learning.plot_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287b5aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_learning.test(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "425d2597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65701163 0.67080684 0.55217423 0.57211771]\n",
      "[0.62820745 0.65535461 0.65535461 0.65535461]\n",
      "[0.65369926 0.54229192 0.65369926 0.65418256]\n"
     ]
    }
   ],
   "source": [
    "q_learning.show_Q_spec((5,6))\n",
    "q_learning.show_Q_spec((3,5))\n",
    "q_learning.show_Q_spec((4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b45a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47eb8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "7\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
